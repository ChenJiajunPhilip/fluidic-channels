{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3e236c62",
      "metadata": {
        "id": "3e236c62"
      },
      "source": [
        "Please see below for the 6 geometric functions:\n",
        "1. Volume of fluid (VOF) --> find_vof: Ratio of fluid region to overall rectangular design space, will range between 0 to 1\n",
        "\n",
        "2. Number of outlets --> num_outlets: Number of outlet channels\n",
        "\n",
        "3. Average outlet channel thickness --> outlet_thicknesses: The average ratio thickness of the outlet channel, with respect to overall height of design space, will range between 0 to 1\n",
        "\n",
        "4. Average inlet channel thickness --> inlet_thicknesses: The average ratio thickness of the inlet channel, with respect to overall height of design space, will range between 0 to 1\n",
        "\n",
        "5. Periemter --> perimeter: The number of pixels that surround the black fluid region, note that this function depends on subtract_inlet() and subtract_outlet() functions\n",
        "\n",
        "6. Connectivity --> connectivity: The number of instances where channels diverge or converge, should be a count integer number"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1ac7c61",
      "metadata": {
        "id": "a1ac7c61"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import openai\n",
        "from openai import OpenAI\n",
        "import os\n",
        "import io\n",
        "import re\n",
        "\n",
        "\n",
        "# === SETUP ===\n",
        "openai.api_key = \"REDACTED\"\n",
        "client = OpenAI(api_key=openai.api_key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4630459",
      "metadata": {
        "id": "e4630459"
      },
      "outputs": [],
      "source": [
        "def find_vof_actual(image_path):\n",
        "  image = Image.open(image_path)\n",
        "  grayscale_image = image.convert('L')\n",
        "  array = np.array(grayscale_image) < 128\n",
        "  vof = np.sum(array) / array.size\n",
        "  return vof\n",
        "\n",
        "def num_outlets_actual(image_path):\n",
        "    image = Image.open(image_path)\n",
        "    grayscale_image = image.convert('L')\n",
        "    array = np.array(grayscale_image) > 128 # Pixels are either 1 (white), or 0 (black)\n",
        "\n",
        "    switch_count = int(np.round(np.sum(array[:-1, -1] != array[1:, -1]) / 2))\n",
        "\n",
        "    return switch_count\n",
        "\n",
        "def outlet_thicknesses_actual(image_path):\n",
        "  image = Image.open(image_path)\n",
        "  grayscale_image = image.convert('L')\n",
        "  array = np.array(grayscale_image) > 128 # Pixels are either 1 (white), or 0 (black)\n",
        "\n",
        "  last_col = array[:, -1]\n",
        "  thicknesses = []\n",
        "  current_run = 0\n",
        "\n",
        "  # Iterate through the last column\n",
        "  for val in last_col:\n",
        "    if val == 0:\n",
        "      current_run += 1\n",
        "    else:\n",
        "      if current_run > 0:\n",
        "        thicknesses.append(current_run/256) # Divide by the number of pixels in a column\n",
        "      current_run = 0  # Reset\n",
        "\n",
        "  if current_run > 0:\n",
        "    thicknesses.append(current_run)\n",
        "\n",
        "  if len(thicknesses) > 0:\n",
        "    return sum(thicknesses) / len(thicknesses) # Average channel thickness\n",
        "    #return sum(thicknesses) # Sum of thicknesses\n",
        "\n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "\n",
        "def inlet_thicknesses_actual(image_path):\n",
        "  image = Image.open(image_path)\n",
        "  grayscale_image = image.convert('L')\n",
        "  array = np.array(grayscale_image) > 128 # Pixels are either 1 (white), or 0 (black)\n",
        "\n",
        "  first_col = array[:, 0]\n",
        "  thicknesses = []\n",
        "  current_run = 0\n",
        "\n",
        "  # Iterate through the first column\n",
        "  for val in first_col:\n",
        "    if val == 0:\n",
        "      current_run += 1\n",
        "    else:\n",
        "      if current_run > 0:\n",
        "        thicknesses.append(current_run/256) # Divide by the number of pixels in a column\n",
        "      current_run = 0  # Reset\n",
        "\n",
        "\n",
        "  if current_run > 0:\n",
        "    thicknesses.append(current_run)\n",
        "\n",
        "  if len(thicknesses) > 0:\n",
        "    return sum(thicknesses) / len(thicknesses) # Average channel thickness\n",
        "    #return sum(thicknesses) # Sum of thicknesses\n",
        "\n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def subtract_inlet_actual(array):\n",
        "  first_col = array[:, 0]\n",
        "  thicknesses = []\n",
        "  current_run = 0\n",
        "\n",
        "  # Iterate through the first column\n",
        "  for val in first_col:\n",
        "    if val == 0:\n",
        "      current_run += 1\n",
        "    else:\n",
        "      if current_run > 0:\n",
        "        thicknesses.append(current_run) # Divide by the number of pixels in a column\n",
        "      current_run = 0  # Reset\n",
        "\n",
        "\n",
        "  if current_run > 0:\n",
        "    thicknesses.append(current_run)\n",
        "\n",
        "  return sum(thicknesses)\n",
        "\n",
        "\n",
        "def subtract_outlet_actual(array):\n",
        "  last_col = array[:, -1]\n",
        "  thicknesses = []\n",
        "  current_run = 0\n",
        "\n",
        "  # Iterate through the last column\n",
        "  for val in last_col:\n",
        "    if val == 0:\n",
        "      current_run += 1\n",
        "    else:\n",
        "      if current_run > 0:\n",
        "        thicknesses.append(current_run) # Divide by the number of pixels in a column\n",
        "      current_run = 0  # Reset\n",
        "\n",
        "  if current_run > 0:\n",
        "    thicknesses.append(current_run)\n",
        "\n",
        "  return sum(thicknesses)\n",
        "\n",
        "def perimeter_actual(image_path):\n",
        "    image = Image.open(image_path)\n",
        "    grayscale_image = image.convert('L')\n",
        "    array = np.array(grayscale_image) > 128 # Pixels are either 1 (white), or 0 (black)\n",
        "\n",
        "    array = array.squeeze()\n",
        "    #Obtain inlet and outlet thicknesses\n",
        "    inlet = subtract_inlet(array)\n",
        "    outlet = subtract_outlet(array)\n",
        "\n",
        "    array = np.pad(array, pad_width=1, mode='constant', constant_values=0)\n",
        "\n",
        "    # Convert the NumPy array to an OpenCV image\n",
        "    img = cv2.cvtColor(array.astype(np.uint8), cv2.COLOR_GRAY2BGR)\n",
        "\n",
        "    # Convert to grayscale and 8-bit unsigned integer\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    gray = cv2.convertScaleAbs(gray)\n",
        "\n",
        "    # Find contours\n",
        "    contours, _ = cv2.findContours(gray, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    #print(f'{len(contours)} contours identified.')\n",
        "\n",
        "    if contours:\n",
        "        # Remove corner points\n",
        "        height, width = array.shape\n",
        "        corner_points = np.array([[0, 0], [width - 1, 0], [width - 1, height - 1], [0, height - 1]])\n",
        "        corner_points_list = corner_points.tolist()\n",
        "\n",
        "        filtered_contours = []\n",
        "\n",
        "        for i, cnt in enumerate(contours):\n",
        "            cnt_array = cnt.reshape(-1, 2)\n",
        "            filtered_cnt = cnt_array[~np.any(np.isin(cnt_array, corner_points_list), axis=1)]\n",
        "            filtered_contours.append(filtered_cnt)\n",
        "\n",
        "\n",
        "            # Extract contour points\n",
        "            x_coords, y_coords = filtered_cnt[:, 0], filtered_cnt[:, 1]\n",
        "\n",
        "            # Plot the contour with a different color\n",
        "            #plt.plot(x_coords, y_coords, color=colors[i % len(colors)], linewidth=2)\n",
        "            #plt.scatter(x_coords, y_coords, color='red', s=3)\n",
        "\n",
        "\n",
        "\n",
        "        # Calculate total perimeter\n",
        "        total_perimeter = sum(cv2.arcLength(cnt, True) for cnt in filtered_contours)\n",
        "        actual_perimeter = total_perimeter - 2*514 - (2 * 258 - inlet - outlet)\n",
        "\n",
        "        # Plot the array (optional)\n",
        "        #plt.imshow(array, cmap='gray', alpha=0.3)  # Add transparency to the image\n",
        "\n",
        "        # Title and show the plot\n",
        "        #plt.title(f\"Perimeter: {actual_perimeter}\")\n",
        "\n",
        "        plt.show()\n",
        "        return actual_perimeter\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "\n",
        "def connectivity_actual(image_path):\n",
        "  image = Image.open(image_path)\n",
        "  grayscale_image = image.convert('L')\n",
        "  array = np.array(grayscale_image) > 128 # Pixels are either 1 (white), or 0 (black)\n",
        "\n",
        "  # Initialize a counter for changes\n",
        "  change_count = 0\n",
        "\n",
        "  # Iterate through each column\n",
        "  for col_index in range(array.shape[1]-1):\n",
        "    previous_column = int(np.round(np.sum(array[:-1, col_index] != array[1:, col_index]) / 2))\n",
        "    current_column = int(np.round(np.sum(array[:-1, col_index+1] != array[1:, col_index+1]) / 2))\n",
        "    if previous_column != current_column:\n",
        "      change_count += 1\n",
        "\n",
        "  return change_count\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "pkhBDQSwtjWT",
      "metadata": {
        "id": "pkhBDQSwtjWT"
      },
      "source": [
        "##test num_outlets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aHROQNjhin1J",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "aHROQNjhin1J",
        "outputId": "e8523288-65c6-4e94-f20a-a7c056632280"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "📤 Upload a PNG image for attempt 1\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-87be8b84-e6d7-46a4-82fa-306f445f7f83\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-87be8b84-e6d7-46a4-82fa-306f445f7f83\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving design_80.png to design_80 (2).png\n",
            "🔁 Calling ChatGPT for num_outlets() function...\n",
            "🧠 Function received from GPT:\n",
            " To solve this problem, we need to analyze the right edge of the given numpy array, which represents an image. The task is to count the number of distinct outlet channels on this edge. An outlet channel can be defined as a contiguous sequence of non-zero pixels (for binary images) or pixels above a certain threshold (for grayscale images) on the right edge of the image.\n",
            "\n",
            "Here's a step-by-step approach to implement the `num_outlets()` function:\n",
            "\n",
            "1. **Extract the Right Edge**: Get the last column of the numpy array, which represents the right edge of the image.\n",
            "\n",
            "2. **Identify Outlets**: Traverse through this column to identify contiguous sequences of non-zero pixels. Each contiguous sequence represents an outlet channel.\n",
            "\n",
            "3. **Count the Outlets**: Keep a count of these sequences.\n",
            "\n",
            "Here's the implementation of the `num_outlets()` function:\n",
            "\n",
            "```python\n",
            "import numpy as np\n",
            "\n",
            "def num_outlets(image):\n",
            "    # Get the number of rows in the image\n",
            "    num_rows = image.shape[0]\n",
            "    \n",
            "    # Extract the right edge of the image\n",
            "    right_edge = image[:, -1]\n",
            "    \n",
            "    # Initialize the outlet count\n",
            "    outlet_count = 0\n",
            "    \n",
            "    # Flag to track if we are in an outlet\n",
            "    in_outlet = False\n",
            "    \n",
            "    # Traverse the right edge to count outlets\n",
            "    for i in range(num_rows):\n",
            "        if right_edge[i] > 0:  # Non-zero pixel indicates part of an outlet\n",
            "            if not in_outlet:\n",
            "                # We have found the start of a new outlet\n",
            "                outlet_count += 1\n",
            "                in_outlet = True\n",
            "        else:\n",
            "            # Zero pixel indicates no outlet\n",
            "            in_outlet = False\n",
            "    \n",
            "    return outlet_count\n",
            "\n",
            "# Example usage:\n",
            "# image = np.array([[0, 0, 0, 1],\n",
            "#                   [0, 0, 0, 1],\n",
            "#                   [0, 0, 0, 0],\n",
            "#                   [0, 0, 0, 1]])\n",
            "# print(num_outlets(image))  # Output: 2\n",
            "```\n",
            "\n",
            "### Explanation:\n",
            "- **right_edge**: This extracts the last column of the image, which is the right edge.\n",
            "- **outlet_count**: This variable keeps track of the number of outlet channels found.\n",
            "- **in_outlet**: A boolean flag to determine if we are currently within an outlet channel.\n",
            "- The loop iterates over each pixel in the right edge. If a non-zero pixel is found and we are not already in an outlet, it indicates the start of a new outlet, and we increment the count. If a zero pixel is encountered, we reset the `in_outlet` flag.\n",
            "\n",
            "This function will correctly count the number of outlet channels on the right edge of a binary or grayscale image represented as a numpy array.\n",
            "\n",
            "✅ Attempt 1:\n",
            "Predicted Outlet Count: 3\n",
            "Actual Outlet Count:    2\n",
            "Absolute Error:         1\n",
            "MAE:                    1.0000\n",
            "\n",
            "⚠️ Not accurate enough. Please upload another image to help improve the model.\n",
            "\n",
            "\n",
            "📤 Upload a PNG image for attempt 2\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-3c0cd1f0-e3ba-4147-b208-df2135319659\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-3c0cd1f0-e3ba-4147-b208-df2135319659\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving design_24.png to design_24.png\n",
            "🔁 Calling ChatGPT for num_outlets() function...\n",
            "🧠 Function received from GPT:\n",
            " To improve the accuracy of the `num_outlets()` function, we need to ensure that we correctly identify and count the outlet channels on the right edge of the image. Here's a refined version of the function:\n",
            "\n",
            "```python\n",
            "import numpy as np\n",
            "\n",
            "def num_outlets(image):\n",
            "    \"\"\"\n",
            "    Counts the number of outlet channels on the right edge of a binary or grayscale image.\n",
            "\n",
            "    Parameters:\n",
            "    image (numpy.ndarray): A 2D numpy array representing a binary or grayscale image.\n",
            "\n",
            "    Returns:\n",
            "    int: The number of outlet channels on the right edge of the image.\n",
            "    \"\"\"\n",
            "    # Ensure the input is a 2D numpy array\n",
            "    if not isinstance(image, np.ndarray) or image.ndim != 2:\n",
            "        raise ValueError(\"Input must be a 2D numpy array.\")\n",
            "\n",
            "    # Get the right edge of the image\n",
            "    right_edge = image[:, -1]\n",
            "\n",
            "    # Identify unique segments on the right edge\n",
            "    # We assume that a channel is represented by a contiguous segment of non-zero values\n",
            "    # We will count transitions from 0 to non-zero as the start of a new channel\n",
            "    outlet_count = 0\n",
            "    in_channel = False\n",
            "\n",
            "    for pixel in right_edge:\n",
            "        if pixel != 0 and not in_channel:\n",
            "            # Start of a new outlet channel\n",
            "            outlet_count += 1\n",
            "            in_channel = True\n",
            "        elif pixel == 0:\n",
            "            # End of a channel\n",
            "            in_channel = False\n",
            "\n",
            "    return outlet_count\n",
            "\n",
            "# Example usage:\n",
            "# image = np.array([[0, 0, 0, 1],\n",
            "#                   [0, 0, 0, 1],\n",
            "#                   [0, 0, 0, 0],\n",
            "#                   [0, 0, 0, 1]])\n",
            "# print(num_outlets(image))  # Output: 2\n",
            "```\n",
            "\n",
            "### Explanation:\n",
            "- **Input Validation**: The function first checks if the input is a 2D numpy array.\n",
            "- **Right Edge Extraction**: It extracts the rightmost column of the image, which represents the right edge.\n",
            "- **Channel Counting**: It iterates over the pixels in the right edge, counting transitions from 0 to non-zero values as the start of a new outlet channel. This approach ensures that each contiguous segment of non-zero values is counted as a single outlet channel.\n",
            "- **Return**: The function returns the total count of outlet channels.\n",
            "\n",
            "This implementation should provide a more accurate count of outlet channels by correctly identifying contiguous segments of non-zero values on the right edge of the image.\n",
            "\n",
            "✅ Attempt 2:\n",
            "Predicted Outlet Count: 3\n",
            "Actual Outlet Count:    2\n",
            "Absolute Error:         1\n",
            "MAE:                    1.0000\n",
            "\n",
            "⚠️ Not accurate enough. Please upload another image to help improve the model.\n",
            "\n",
            "\n",
            "📤 Upload a PNG image for attempt 3\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-733b1132-06c0-4af6-abd5-5c9ef84158c0\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-733b1132-06c0-4af6-abd5-5c9ef84158c0\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving design_19.png to design_19.png\n",
            "🔁 Calling ChatGPT for num_outlets() function...\n",
            "🧠 Function received from GPT:\n",
            " To improve the accuracy of the `num_outlets()` function, we need to ensure that we correctly identify and count the outlet channels on the right edge of the image. Here's a refined approach to achieve this:\n",
            "\n",
            "1. **Identify Outlets**: We will scan the rightmost column of the image to identify continuous segments of non-zero values, which represent outlet channels.\n",
            "\n",
            "2. **Count Outlets**: We will count these continuous segments to determine the number of outlet channels.\n",
            "\n",
            "Here's the implementation of the `num_outlets()` function:\n",
            "\n",
            "```python\n",
            "import numpy as np\n",
            "\n",
            "def num_outlets(image):\n",
            "    # Ensure the input is a numpy array\n",
            "    if not isinstance(image, np.ndarray):\n",
            "        raise ValueError(\"Input must be a numpy array.\")\n",
            "    \n",
            "    # Get the rightmost column of the image\n",
            "    right_edge = image[:, -1]\n",
            "    \n",
            "    # Initialize variables to count outlets\n",
            "    outlet_count = 0\n",
            "    in_outlet = False\n",
            "    \n",
            "    # Iterate over the right edge to count continuous non-zero segments\n",
            "    for pixel in right_edge:\n",
            "        if pixel > 0:  # Assuming non-zero values indicate a channel\n",
            "            if not in_outlet:\n",
            "                # Start of a new outlet\n",
            "                outlet_count += 1\n",
            "                in_outlet = True\n",
            "        else:\n",
            "            # End of a current outlet\n",
            "            in_outlet = False\n",
            "    \n",
            "    return outlet_count\n",
            "\n",
            "# Example usage:\n",
            "# image = np.array([[0, 0, 0, 1],\n",
            "#                   [0, 0, 0, 1],\n",
            "#                   [0, 0, 0, 0],\n",
            "#                   [0, 0, 0, 1]])\n",
            "# print(num_outlets(image))  # Output should be 2\n",
            "```\n",
            "\n",
            "### Explanation:\n",
            "- **Right Edge Extraction**: We extract the rightmost column of the image using `image[:, -1]`.\n",
            "- **Outlet Detection**: We iterate through this column, checking for transitions from zero to non-zero values to detect the start of an outlet.\n",
            "- **Counting**: We increment the outlet count each time we detect the start of a new outlet and ensure we don't double-count by using a flag (`in_outlet`) to track whether we are currently within an outlet.\n",
            "\n",
            "This approach should accurately count the number of outlet channels on the right edge of the image.\n",
            "\n",
            "✅ Attempt 3:\n",
            "Predicted Outlet Count: 4\n",
            "Actual Outlet Count:    3\n",
            "Absolute Error:         1\n",
            "MAE:                    1.0000\n",
            "\n",
            "⚠️ Not accurate enough. Please upload another image to help improve the model.\n",
            "\n",
            "\n",
            "📤 Upload a PNG image for attempt 4\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-2846d552-d1a4-40b6-8cb6-c3e0e9bdba3f\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-2846d552-d1a4-40b6-8cb6-c3e0e9bdba3f\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving design_195.png to design_195.png\n",
            "🔁 Calling ChatGPT for num_outlets() function...\n",
            "🧠 Function received from GPT:\n",
            " To improve the accuracy of the `num_outlets()` function, we need to ensure that we correctly identify and count the outlet channels on the right edge of the image. An outlet channel is defined as a continuous segment of non-zero pixels on the right edge of the image. Here's how you can implement this function:\n",
            "\n",
            "```python\n",
            "import numpy as np\n",
            "\n",
            "def num_outlets(image):\n",
            "    \"\"\"\n",
            "    Counts the number of outlet channels on the right edge of a binary or grayscale image.\n",
            "\n",
            "    Parameters:\n",
            "    image (numpy.ndarray): A 2D numpy array representing a binary or grayscale image.\n",
            "\n",
            "    Returns:\n",
            "    int: The number of outlet channels on the right edge of the image.\n",
            "    \"\"\"\n",
            "    # Get the right edge of the image\n",
            "    right_edge = image[:, -1]\n",
            "    \n",
            "    # Initialize the count of outlet channels\n",
            "    outlet_count = 0\n",
            "    \n",
            "    # Flag to track if we are in an outlet channel\n",
            "    in_outlet = False\n",
            "    \n",
            "    # Iterate over the right edge to count outlet channels\n",
            "    for pixel in right_edge:\n",
            "        if pixel > 0:  # Non-zero pixel indicates part of an outlet\n",
            "            if not in_outlet:\n",
            "                # We have found the start of a new outlet channel\n",
            "                outlet_count += 1\n",
            "                in_outlet = True\n",
            "        else:\n",
            "            # Zero pixel indicates the end of an outlet channel\n",
            "            in_outlet = False\n",
            "    \n",
            "    return outlet_count\n",
            "\n",
            "# Example usage:\n",
            "# image = np.array([[0, 0, 0, 1],\n",
            "#                   [0, 0, 0, 1],\n",
            "#                   [0, 0, 0, 0],\n",
            "#                   [0, 0, 0, 1]])\n",
            "# print(num_outlets(image))  # Output: 2\n",
            "```\n",
            "\n",
            "### Explanation:\n",
            "- **Right Edge Extraction**: We extract the rightmost column of the image using `image[:, -1]`.\n",
            "- **Outlet Counting**: We iterate through the pixels of the right edge. We use a flag `in_outlet` to track whether we are currently within an outlet channel.\n",
            "  - If we encounter a non-zero pixel and `in_outlet` is `False`, it means we've found the start of a new outlet channel, so we increment the `outlet_count` and set `in_outlet` to `True`.\n",
            "  - If we encounter a zero pixel, we set `in_outlet` to `False`, indicating the end of an outlet channel.\n",
            "\n",
            "This approach ensures that we accurately count each distinct outlet channel on the right edge of the image.\n",
            "\n",
            "✅ Attempt 4:\n",
            "Predicted Outlet Count: 3\n",
            "Actual Outlet Count:    2\n",
            "Absolute Error:         1\n",
            "MAE:                    1.0000\n",
            "\n",
            "⚠️ Not accurate enough. Please upload another image to help improve the model.\n",
            "\n",
            "\n",
            "📤 Upload a PNG image for attempt 5\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-876cb439-2e92-497d-b561-2b802c0fffff\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-876cb439-2e92-497d-b561-2b802c0fffff\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-10-3022492551.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0mattempts\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\n📤 Upload a PNG image for attempt {attempts + 1}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m     \u001b[0mimage_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupload_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'L'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-10-3022492551.py\u001b[0m in \u001b[0;36mupload_image\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;31m# === Upload image ===\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mupload_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0muploaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0muploaded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m(target_dir)\u001b[0m\n\u001b[1;32m     70\u001b[0m   \"\"\"\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m   \u001b[0muploaded_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_upload_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmultiple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m   \u001b[0;31m# Mapping from original filename to filename as saved locally.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m   \u001b[0mlocal_filenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36m_upload_files\u001b[0;34m(multiple)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m   \u001b[0;31m# First result is always an indication that the file picker has completed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m   result = _output.eval_js(\n\u001b[0m\u001b[1;32m    165\u001b[0m       'google.colab._files._uploadFiles(\"{input_id}\", \"{output_id}\")'.format(\n\u001b[1;32m    166\u001b[0m           \u001b[0minput_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result, timeout_sec)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     if (\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import openai\n",
        "from openai import OpenAI\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import os\n",
        "import io\n",
        "import re\n",
        "\n",
        "\n",
        "# === SETUP ===\n",
        "openai.api_key = \"REDACTED\"\n",
        "client = OpenAI(api_key=openai.api_key)\n",
        "\n",
        "base_prompt = \"\"\"Write a Python function named `num_outlets()` that counts the number of outlet channels in a numpy array representing a binary or grayscale image.\n",
        "Inlet channels are always located on the **left** edge of the image, and outlet channels are located on the **right** edge of the image.\n",
        "Return the number of **outlet** channels as an integer. Do not count inlets. The input is a numpy array.\"\"\"\n",
        "\n",
        "\n",
        "# === Extract Python code from GPT output ===\n",
        "def extract_python_code(response_text):\n",
        "    matches = re.findall(r\"```(?:python)?(.*?)```\", response_text, re.DOTALL)\n",
        "    return matches[0].strip() if matches else response_text.strip()\n",
        "\n",
        "# === Prompt GPT to generate num_outlets() ===\n",
        "def get_outlet_function_from_gpt(prompt):\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        temperature=0\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "# === Upload image ===\n",
        "def upload_image():\n",
        "    uploaded = files.upload()\n",
        "    for filename in uploaded.keys():\n",
        "        return filename\n",
        "\n",
        "# === Run generated function on image ===\n",
        "def run_generated_outlet_function(code_str, image_array):\n",
        "    code_str = extract_python_code(code_str)\n",
        "    local_vars = {}\n",
        "    exec(code_str, globals(), local_vars)\n",
        "    num_outlets_func = local_vars.get(\"num_outlets\")\n",
        "    if num_outlets_func is None:\n",
        "        raise ValueError(\"Function `num_outlets()` not found.\")\n",
        "    return num_outlets_func(image_array)\n",
        "\n",
        "# === MAIN LOOP ===\n",
        "attempts = 0\n",
        "mae_list = []\n",
        "all_errors = []\n",
        "\n",
        "while attempts < 10:\n",
        "    print(f\"\\n📤 Upload a PNG image for attempt {attempts + 1}\")\n",
        "    image_path = upload_image()\n",
        "\n",
        "    image = Image.open(image_path).convert('L')\n",
        "    image_array = np.array(image)\n",
        "\n",
        "    actual_count = num_outlets_actual(image_path)\n",
        "\n",
        "    if attempts == 0:\n",
        "        prompt = base_prompt\n",
        "    else:\n",
        "        feedback = f\"\\n\\nFeedback: Your previous estimate had MAE = {mae_list[-1]:.4f}. Please improve the accuracy of your num_outlets() function.\"\n",
        "        prompt = base_prompt + feedback\n",
        "\n",
        "    print(\"🔁 Calling ChatGPT for num_outlets() function...\")\n",
        "    code = get_outlet_function_from_gpt(prompt)\n",
        "    print(\"🧠 Function received from GPT:\\n\", code)\n",
        "\n",
        "    try:\n",
        "        pred_count = run_generated_outlet_function(code, image_array)\n",
        "    except Exception as e:\n",
        "        print(\"❌ Error running the generated function:\", e)\n",
        "        mae_list.append(10)  # Penalize failure\n",
        "        attempts += 1\n",
        "        continue\n",
        "\n",
        "    error = abs(pred_count - actual_count)\n",
        "    all_errors.append(error)\n",
        "    mae = error if attempts == 0 else np.mean(all_errors)\n",
        "    mae_list.append(mae)\n",
        "\n",
        "    print(f\"\\n✅ Attempt {attempts + 1}:\")\n",
        "    print(f\"Predicted Outlet Count: {pred_count}\")\n",
        "    print(f\"Actual Outlet Count:    {actual_count}\")\n",
        "    print(f\"Absolute Error:         {error}\")\n",
        "    print(f\"MAE:                    {mae:.4f}\")\n",
        "\n",
        "    if mae < 0.1:\n",
        "        print(\"\\n🎯 Success: MAE is acceptable. Returning the final num_outlets() function:\\n\")\n",
        "        print(extract_python_code(code))\n",
        "        break\n",
        "    else:\n",
        "        print(\"\\n⚠️ Not accurate enough. Please upload another image to help improve the model.\\n\")\n",
        "\n",
        "    attempts += 1\n",
        "\n",
        "# === PLOT MAE ===\n",
        "plt.plot(range(1, len(mae_list)+1), mae_list, marker='o')\n",
        "plt.title(\"Mean Absolute Error (MAE) for num_outlets() over Attempts\")\n",
        "plt.xlabel(\"Attempt\")\n",
        "plt.ylabel(\"MAE\")\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "YiJNEDNWt11y",
      "metadata": {
        "id": "YiJNEDNWt11y"
      },
      "source": [
        "##Test average outlet channel thickness"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "xSBCCC3GuAc6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xSBCCC3GuAc6",
        "outputId": "5658039d-a57c-42eb-c5d6-438cee75f778"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "📤 Upload a PNG image for attempt 1\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-1d969a6e-7c56-4469-81b5-2a49126ab572\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-1d969a6e-7c56-4469-81b5-2a49126ab572\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving design_80.png to design_80 (8).png\n",
            "🔁 Calling ChatGPT for outlet_thicknesses() function...\n",
            "🧠 Function received from GPT:\n",
            " To calculate the average thickness of outlet channels in a binary or grayscale image, we can follow these steps:\n",
            "\n",
            "1. Identify the outlet channels touching the rightmost edge of the image.\n",
            "2. Measure the vertical span of each outlet channel.\n",
            "3. Normalize the thickness by dividing by the total height of the image.\n",
            "4. Calculate the average thickness of all outlet channels.\n",
            "\n",
            "Here's a Python function that implements this logic using the `numpy` library:\n",
            "\n",
            "```python\n",
            "import numpy as np\n",
            "from scipy.ndimage import label\n",
            "\n",
            "def outlet_thicknesses(image):\n",
            "    \"\"\"\n",
            "    Calculate the average thickness of outlet channels in a binary or grayscale image.\n",
            "\n",
            "    Parameters:\n",
            "    - image: numpy array representing the binary or grayscale image.\n",
            "\n",
            "    Returns:\n",
            "    - Average outlet thickness as a float between 0 and 1.\n",
            "    \"\"\"\n",
            "    # Ensure the image is a binary image\n",
            "    if image.dtype != np.bool:\n",
            "        # Convert grayscale to binary by thresholding\n",
            "        image = image > 0\n",
            "\n",
            "    # Get the rightmost column\n",
            "    rightmost_column = image[:, -1]\n",
            "\n",
            "    # Label connected components in the rightmost column\n",
            "    labeled_array, num_features = label(rightmost_column)\n",
            "\n",
            "    # Calculate the thickness of each outlet channel\n",
            "    thicknesses = []\n",
            "    for i in range(1, num_features + 1):\n",
            "        # Find the vertical span of the current outlet channel\n",
            "        positions = np.where(labeled_array == i)[0]\n",
            "        if positions.size > 0:\n",
            "            thickness = positions[-1] - positions[0] + 1\n",
            "            thicknesses.append(thickness)\n",
            "\n",
            "    # Normalize thicknesses by the height of the image\n",
            "    height = image.shape[0]\n",
            "    normalized_thicknesses = [thickness / height for thickness in thicknesses]\n",
            "\n",
            "    # Calculate the average thickness\n",
            "    if normalized_thicknesses:\n",
            "        average_thickness = np.mean(normalized_thicknesses)\n",
            "    else:\n",
            "        average_thickness = 0.0\n",
            "\n",
            "    return average_thickness\n",
            "\n",
            "# Example usage:\n",
            "# image = np.array([[0, 0, 0, 1],\n",
            "#                   [0, 0, 0, 1],\n",
            "#                   [0, 0, 0, 0],\n",
            "#                   [0, 0, 0, 1]])\n",
            "# print(outlet_thicknesses(image))  # Output: 0.75\n",
            "```\n",
            "\n",
            "### Explanation:\n",
            "- **Binary Conversion**: The function first ensures that the image is binary. If the image is grayscale, it converts it to binary by thresholding (assuming any non-zero value is part of a channel).\n",
            "- **Labeling**: It uses `scipy.ndimage.label` to identify connected components in the rightmost column of the image.\n",
            "- **Thickness Calculation**: For each labeled component, it calculates the vertical span (thickness) and normalizes it by the image height.\n",
            "- **Average Calculation**: Finally, it computes the average of these normalized thicknesses. If there are no outlet channels, it returns 0.0.\n",
            "\n",
            "✅ Attempt 1:\n",
            "Predicted Avg Thickness: 0.2109\n",
            "Actual Avg Thickness:    0.1836\n",
            "Absolute Error:          0.0273\n",
            "MAE:                     0.0273\n",
            "\n",
            "🎯 Success: MAE is acceptable. Returning the final outlet_thicknesses() function:\n",
            "\n",
            "import numpy as np\n",
            "from scipy.ndimage import label\n",
            "\n",
            "def outlet_thicknesses(image):\n",
            "    \"\"\"\n",
            "    Calculate the average thickness of outlet channels in a binary or grayscale image.\n",
            "\n",
            "    Parameters:\n",
            "    - image: numpy array representing the binary or grayscale image.\n",
            "\n",
            "    Returns:\n",
            "    - Average outlet thickness as a float between 0 and 1.\n",
            "    \"\"\"\n",
            "    # Ensure the image is a binary image\n",
            "    if image.dtype != np.bool:\n",
            "        # Convert grayscale to binary by thresholding\n",
            "        image = image > 0\n",
            "\n",
            "    # Get the rightmost column\n",
            "    rightmost_column = image[:, -1]\n",
            "\n",
            "    # Label connected components in the rightmost column\n",
            "    labeled_array, num_features = label(rightmost_column)\n",
            "\n",
            "    # Calculate the thickness of each outlet channel\n",
            "    thicknesses = []\n",
            "    for i in range(1, num_features + 1):\n",
            "        # Find the vertical span of the current outlet channel\n",
            "        positions = np.where(labeled_array == i)[0]\n",
            "        if positions.size > 0:\n",
            "            thickness = positions[-1] - positions[0] + 1\n",
            "            thicknesses.append(thickness)\n",
            "\n",
            "    # Normalize thicknesses by the height of the image\n",
            "    height = image.shape[0]\n",
            "    normalized_thicknesses = [thickness / height for thickness in thicknesses]\n",
            "\n",
            "    # Calculate the average thickness\n",
            "    if normalized_thicknesses:\n",
            "        average_thickness = np.mean(normalized_thicknesses)\n",
            "    else:\n",
            "        average_thickness = 0.0\n",
            "\n",
            "    return average_thickness\n",
            "\n",
            "# Example usage:\n",
            "# image = np.array([[0, 0, 0, 1],\n",
            "#                   [0, 0, 0, 1],\n",
            "#                   [0, 0, 0, 0],\n",
            "#                   [0, 0, 0, 1]])\n",
            "# print(outlet_thicknesses(image))  # Output: 0.75\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install --upgrade openai matplotlib scipy --quiet\n",
        "import openai\n",
        "from openai import OpenAI\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import os\n",
        "import io\n",
        "import re\n",
        "\n",
        "\n",
        "# === SETUP ===\n",
        "openai.api_key = \"REDACTED\"\n",
        "client = OpenAI(api_key=openai.api_key)\n",
        "base_prompt = \"\"\"Write a Python function called `outlet_thicknesses()` that calculates the average thickness of outlet channels in a binary or grayscale image represented as a numpy array.\n",
        "Inlet channels are on the left and outlet channels are on the right side of the image.\n",
        "Outlet thickness should be measured as the vertical span (in normalized units) of each outlet region touching the rightmost edge.\n",
        "Return the average outlet thickness as a float between 0 and 1.\"\"\"\n",
        "\n",
        "# === Ground truth function (GPT doesn't see this) ===\n",
        "def outlet_thicknesses_actual(image_path):\n",
        "    image = Image.open(image_path)\n",
        "    grayscale_image = image.convert('L')\n",
        "    array = np.array(grayscale_image) > 128\n",
        "\n",
        "    last_col = array[:, -1]\n",
        "    thicknesses = []\n",
        "    current_run = 0\n",
        "\n",
        "    for val in last_col:\n",
        "        if val == 0:\n",
        "            current_run += 1\n",
        "        else:\n",
        "            if current_run > 0:\n",
        "                thicknesses.append(current_run / 256)\n",
        "            current_run = 0\n",
        "\n",
        "    if current_run > 0:\n",
        "        thicknesses.append(current_run / 256)\n",
        "\n",
        "    if len(thicknesses) > 0:\n",
        "        return sum(thicknesses) / len(thicknesses)\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "# === Extract Python code from GPT response ===\n",
        "def extract_python_code(response_text):\n",
        "    matches = re.findall(r\"```(?:python)?(.*?)```\", response_text, re.DOTALL)\n",
        "    return matches[0].strip() if matches else response_text.strip()\n",
        "\n",
        "# === Prompt GPT to write outlet_thicknesses() ===\n",
        "def get_thickness_function_from_gpt(prompt):\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        temperature=0\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "# === Upload image ===\n",
        "def upload_image():\n",
        "    uploaded = files.upload()\n",
        "    for filename in uploaded.keys():\n",
        "        return filename\n",
        "\n",
        "# === Run the generated function safely with patching ===\n",
        "def run_generated_thickness_function(code_str, image_array):\n",
        "    import scipy.ndimage  # ensure module is loaded\n",
        "    from scipy.ndimage import label as scipy_label\n",
        "\n",
        "    code_str = extract_python_code(code_str)\n",
        "\n",
        "    # Prepend import if it's missing from code block (safe fallback)\n",
        "    if \"label(\" in code_str and \"from scipy.ndimage import label\" not in code_str:\n",
        "        code_str = \"from scipy.ndimage import label\\n\" + code_str\n",
        "\n",
        "    # Make `label` available globally in case it's not in the code\n",
        "    globals()[\"label\"] = scipy_label\n",
        "\n",
        "    local_vars = {}\n",
        "    try:\n",
        "        exec(code_str, globals(), local_vars)\n",
        "        outlet_thicknesses = local_vars.get(\"outlet_thicknesses\")\n",
        "        if outlet_thicknesses is None:\n",
        "            raise ValueError(\"Function `outlet_thicknesses()` not found.\")\n",
        "        return outlet_thicknesses(image_array)\n",
        "    except Exception as e:\n",
        "        raise RuntimeError(f\"Failed to execute generated code: {e}\")\n",
        "\n",
        "\n",
        "# === MAIN LOOP ===\n",
        "attempts = 0\n",
        "mae_list = []\n",
        "all_errors = []\n",
        "\n",
        "while attempts < 10:\n",
        "    print(f\"\\n📤 Upload a PNG image for attempt {attempts + 1}\")\n",
        "    image_path = upload_image()\n",
        "\n",
        "    image = Image.open(image_path).convert('L')\n",
        "    image_array = np.array(image)\n",
        "\n",
        "    actual_thickness = outlet_thicknesses_actual(image_path)\n",
        "\n",
        "    if attempts == 0:\n",
        "        prompt = base_prompt\n",
        "    else:\n",
        "        feedback = f\"\\n\\nFeedback: Your previous estimate had MAE = {mae_list[-1]:.4f}. Please improve the outlet_thicknesses() function.\"\n",
        "        prompt = base_prompt + feedback\n",
        "\n",
        "    print(\"🔁 Calling ChatGPT for outlet_thicknesses() function...\")\n",
        "    code = get_thickness_function_from_gpt(prompt)\n",
        "    print(\"🧠 Function received from GPT:\\n\", code)\n",
        "\n",
        "    try:\n",
        "        pred_thickness = run_generated_thickness_function(code, image_array)\n",
        "    except Exception as e:\n",
        "        print(\"❌ Error running the generated function:\", e)\n",
        "        mae_list.append(1.0)\n",
        "        attempts += 1\n",
        "        continue\n",
        "\n",
        "    error = abs(pred_thickness - actual_thickness)\n",
        "    all_errors.append(error)\n",
        "    mae = error if attempts == 0 else np.mean(all_errors)\n",
        "    mae_list.append(mae)\n",
        "\n",
        "    print(f\"\\n✅ Attempt {attempts + 1}:\")\n",
        "    print(f\"Predicted Avg Thickness: {pred_thickness:.4f}\")\n",
        "    print(f\"Actual Avg Thickness:    {actual_thickness:.4f}\")\n",
        "    print(f\"Absolute Error:          {error:.4f}\")\n",
        "    print(f\"MAE:                     {mae:.4f}\")\n",
        "\n",
        "    if mae < 0.1:\n",
        "        print(\"\\n🎯 Success: MAE is acceptable. Returning the final outlet_thicknesses() function:\\n\")\n",
        "        print(extract_python_code(code))\n",
        "        break\n",
        "    else:\n",
        "        print(\"\\n⚠️ Not accurate enough. Please upload another image to improve the function.\\n\")\n",
        "\n",
        "    attempts += 1\n",
        "\n",
        "# === PLOT MAE ===\n",
        "plt.plot(range(1, len(mae_list)+1), mae_list, marker='o')\n",
        "plt.title(\"Mean Absolute Error (MAE) for outlet_thicknesses()\")\n",
        "plt.xlabel(\"Attempt\")\n",
        "plt.ylabel(\"MAE\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eTojn0SjhIGX",
      "metadata": {
        "id": "eTojn0SjhIGX"
      },
      "source": [
        "##Test average intlet channel thickness"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FKOGqLGuhLat",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "FKOGqLGuhLat",
        "outputId": "fb741f44-caaf-4db0-9b5b-1479619c1967"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "📤 Upload a PNG image for attempt 1\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c855b650-ca33-4275-9fdc-b98afc3e4ea5\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-c855b650-ca33-4275-9fdc-b98afc3e4ea5\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving design_80.png to design_80 (1).png\n",
            "🔁 Calling ChatGPT for inlet_thicknesses() function...\n",
            "🧠 Function received from GPT:\n",
            " To calculate the average thickness of inlet channels in a binary or grayscale image, we need to identify the connected regions on the left edge of the image and measure their vertical spans. Here's a step-by-step implementation of the `inlet_thicknesses()` function:\n",
            "\n",
            "```python\n",
            "import numpy as np\n",
            "from scipy.ndimage import label\n",
            "\n",
            "def inlet_thicknesses(image):\n",
            "    \"\"\"\n",
            "    Calculate the average thickness of inlet channels on the left edge of the image.\n",
            "\n",
            "    Parameters:\n",
            "    - image: A 2D numpy array representing a binary or grayscale image.\n",
            "\n",
            "    Returns:\n",
            "    - A float representing the average inlet thickness, normalized between 0 and 1.\n",
            "    \"\"\"\n",
            "    # Ensure the image is binary\n",
            "    if image.dtype != np.bool:\n",
            "        # Convert grayscale to binary using a threshold\n",
            "        threshold = image.max() / 2\n",
            "        binary_image = image > threshold\n",
            "    else:\n",
            "        binary_image = image\n",
            "\n",
            "    # Extract the leftmost column\n",
            "    left_edge = binary_image[:, 0]\n",
            "\n",
            "    # Label connected components on the left edge\n",
            "    labeled_array, num_features = label(left_edge)\n",
            "\n",
            "    # Calculate the thickness of each inlet channel\n",
            "    thicknesses = []\n",
            "    for i in range(1, num_features + 1):\n",
            "        # Find the vertical span of each labeled region\n",
            "        positions = np.where(labeled_array == i)[0]\n",
            "        if positions.size > 0:\n",
            "            thickness = positions[-1] - positions[0] + 1\n",
            "            thicknesses.append(thickness)\n",
            "\n",
            "    # Normalize thicknesses by the height of the image\n",
            "    image_height = image.shape[0]\n",
            "    normalized_thicknesses = [t / image_height for t in thicknesses]\n",
            "\n",
            "    # Calculate the average thickness\n",
            "    if normalized_thicknesses:\n",
            "        average_thickness = np.mean(normalized_thicknesses)\n",
            "    else:\n",
            "        average_thickness = 0.0\n",
            "\n",
            "    return average_thickness\n",
            "\n",
            "# Example usage:\n",
            "# image = np.array([[0, 0, 0], [1, 0, 0], [1, 0, 0], [0, 0, 0]])\n",
            "# print(inlet_thicknesses(image))  # Output: 0.5\n",
            "```\n",
            "\n",
            "### Explanation:\n",
            "\n",
            "1. **Binary Conversion**: The function first checks if the image is binary. If not, it converts a grayscale image to binary using a threshold (half of the maximum pixel value).\n",
            "\n",
            "2. **Left Edge Extraction**: It extracts the leftmost column of the image, which represents the potential inlet channels.\n",
            "\n",
            "3. **Labeling**: The `scipy.ndimage.label` function is used to label connected components in the left edge column.\n",
            "\n",
            "4. **Thickness Calculation**: For each labeled region, the function calculates the vertical span (thickness) by finding the difference between the maximum and minimum indices of the region.\n",
            "\n",
            "5. **Normalization**: The thicknesses are normalized by dividing by the total height of the image.\n",
            "\n",
            "6. **Average Calculation**: Finally, the function computes the average of the normalized thicknesses. If there are no inlet channels, it returns 0.0.\n",
            "\n",
            "This function should work for both binary and grayscale images, providing a normalized average thickness of inlet channels.\n",
            "\n",
            "✅ Attempt 1:\n",
            "Predicted Avg Inlet Thickness: 0.2949\n",
            "Actual Avg Inlet Thickness:    0.4102\n",
            "Absolute Error:                0.1152\n",
            "MAE:                           0.1152\n",
            "\n",
            "⚠️ Not accurate enough. Please upload another image to improve the function.\n",
            "\n",
            "\n",
            "📤 Upload a PNG image for attempt 2\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-e3c382bd-79e0-439e-b53d-c8be00de7455\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-e3c382bd-79e0-439e-b53d-c8be00de7455\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving design_11.png to design_11.png\n",
            "🔁 Calling ChatGPT for inlet_thicknesses() function...\n",
            "🧠 Function received from GPT:\n",
            " To improve the `inlet_thicknesses()` function, we need to ensure that we accurately identify and measure the vertical span of inlet channels touching the left edge of the image. The function should handle both binary and grayscale images, where inlet channels are represented by non-zero values. Here's an improved version of the function:\n",
            "\n",
            "```python\n",
            "import numpy as np\n",
            "from scipy.ndimage import label\n",
            "\n",
            "def inlet_thicknesses(image):\n",
            "    \"\"\"\n",
            "    Calculate the average thickness of inlet channels in a binary or grayscale image.\n",
            "\n",
            "    Parameters:\n",
            "    - image: A 2D numpy array representing the image.\n",
            "\n",
            "    Returns:\n",
            "    - A float representing the average inlet thickness, normalized between 0 and 1.\n",
            "    \"\"\"\n",
            "    # Ensure the image is a numpy array\n",
            "    image = np.asarray(image)\n",
            "    \n",
            "    # Threshold the image to binary if it's grayscale\n",
            "    if image.dtype != bool:\n",
            "        image = image > 0  # Convert to binary: True for inlet channels, False otherwise\n",
            "\n",
            "    # Extract the leftmost column\n",
            "    left_edge = image[:, 0]\n",
            "\n",
            "    # Label connected components on the left edge\n",
            "    labeled_array, num_features = label(left_edge)\n",
            "\n",
            "    # Calculate the thickness of each inlet channel\n",
            "    inlet_thicknesses = []\n",
            "    for i in range(1, num_features + 1):\n",
            "        # Find the vertical span of each labeled region\n",
            "        region_indices = np.where(labeled_array == i)[0]\n",
            "        if region_indices.size > 0:\n",
            "            thickness = region_indices[-1] - region_indices[0] + 1\n",
            "            inlet_thicknesses.append(thickness)\n",
            "\n",
            "    # Normalize thicknesses by the height of the image\n",
            "    image_height = image.shape[0]\n",
            "    normalized_thicknesses = [thickness / image_height for thickness in inlet_thicknesses]\n",
            "\n",
            "    # Calculate the average thickness\n",
            "    if normalized_thicknesses:\n",
            "        average_thickness = np.mean(normalized_thicknesses)\n",
            "    else:\n",
            "        average_thickness = 0.0\n",
            "\n",
            "    return average_thickness\n",
            "\n",
            "# Example usage:\n",
            "# image = np.array([[0, 0, 0], [1, 0, 0], [1, 0, 0], [0, 0, 0]])\n",
            "# print(inlet_thicknesses(image))  # Output should be 0.5 for this example\n",
            "```\n",
            "\n",
            "### Key Improvements:\n",
            "1. **Binary Conversion**: The function now explicitly converts grayscale images to binary by thresholding, ensuring that any non-zero pixel is considered part of an inlet channel.\n",
            "2. **Connected Component Labeling**: We use `scipy.ndimage.label` to identify connected components on the left edge, which helps in accurately measuring the vertical span of each inlet channel.\n",
            "3. **Normalization**: The thickness of each inlet channel is normalized by the height of the image to ensure the result is between 0 and 1.\n",
            "4. **Robustness**: The function handles cases where there are no inlet channels by returning an average thickness of 0.0.\n",
            "\n",
            "This approach should provide a more accurate estimate of the average inlet thickness, reducing the mean absolute error (MAE) in your application.\n",
            "\n",
            "✅ Attempt 2:\n",
            "Predicted Avg Inlet Thickness: 0.1348\n",
            "Actual Avg Inlet Thickness:    0.1536\n",
            "Absolute Error:                0.0189\n",
            "MAE:                           0.0671\n",
            "\n",
            "🎯 Success: MAE is acceptable. Returning the final inlet_thicknesses() function:\n",
            "\n",
            "import numpy as np\n",
            "from scipy.ndimage import label\n",
            "\n",
            "def inlet_thicknesses(image):\n",
            "    \"\"\"\n",
            "    Calculate the average thickness of inlet channels in a binary or grayscale image.\n",
            "\n",
            "    Parameters:\n",
            "    - image: A 2D numpy array representing the image.\n",
            "\n",
            "    Returns:\n",
            "    - A float representing the average inlet thickness, normalized between 0 and 1.\n",
            "    \"\"\"\n",
            "    # Ensure the image is a numpy array\n",
            "    image = np.asarray(image)\n",
            "    \n",
            "    # Threshold the image to binary if it's grayscale\n",
            "    if image.dtype != bool:\n",
            "        image = image > 0  # Convert to binary: True for inlet channels, False otherwise\n",
            "\n",
            "    # Extract the leftmost column\n",
            "    left_edge = image[:, 0]\n",
            "\n",
            "    # Label connected components on the left edge\n",
            "    labeled_array, num_features = label(left_edge)\n",
            "\n",
            "    # Calculate the thickness of each inlet channel\n",
            "    inlet_thicknesses = []\n",
            "    for i in range(1, num_features + 1):\n",
            "        # Find the vertical span of each labeled region\n",
            "        region_indices = np.where(labeled_array == i)[0]\n",
            "        if region_indices.size > 0:\n",
            "            thickness = region_indices[-1] - region_indices[0] + 1\n",
            "            inlet_thicknesses.append(thickness)\n",
            "\n",
            "    # Normalize thicknesses by the height of the image\n",
            "    image_height = image.shape[0]\n",
            "    normalized_thicknesses = [thickness / image_height for thickness in inlet_thicknesses]\n",
            "\n",
            "    # Calculate the average thickness\n",
            "    if normalized_thicknesses:\n",
            "        average_thickness = np.mean(normalized_thicknesses)\n",
            "    else:\n",
            "        average_thickness = 0.0\n",
            "\n",
            "    return average_thickness\n",
            "\n",
            "# Example usage:\n",
            "# image = np.array([[0, 0, 0], [1, 0, 0], [1, 0, 0], [0, 0, 0]])\n",
            "# print(inlet_thicknesses(image))  # Output should be 0.5 for this example\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# === Prompt for GPT ===\n",
        "base_prompt = \"\"\"Write a Python function called `inlet_thicknesses()` that calculates the average thickness of inlet channels in a binary or grayscale image represented as a numpy array.\n",
        "Inlet channels are located on the **left edge** of the image, and outlet channels are on the right.\n",
        "Inlet thickness should be measured as the vertical span (in normalized units) of each inlet region touching the leftmost edge.\n",
        "Return the average inlet thickness as a float between 0 and 1.\"\"\"\n",
        "\n",
        "# === Ground Truth Function ===\n",
        "def inlet_thicknesses_actual(image_path):\n",
        "    image = Image.open(image_path)\n",
        "    grayscale_image = image.convert('L')\n",
        "    array = np.array(grayscale_image) > 128\n",
        "\n",
        "    first_col = array[:, 0]\n",
        "    thicknesses = []\n",
        "    current_run = 0\n",
        "\n",
        "    for val in first_col:\n",
        "        if val == 0:\n",
        "            current_run += 1\n",
        "        else:\n",
        "            if current_run > 0:\n",
        "                thicknesses.append(current_run / 256)\n",
        "            current_run = 0\n",
        "\n",
        "    if current_run > 0:\n",
        "        thicknesses.append(current_run / 256)\n",
        "\n",
        "    if len(thicknesses) > 0:\n",
        "        return sum(thicknesses) / len(thicknesses)\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "# === Helpers ===\n",
        "def extract_python_code(response_text):\n",
        "    matches = re.findall(r\"```(?:python)?(.*?)```\", response_text, re.DOTALL)\n",
        "    return matches[0].strip() if matches else response_text.strip()\n",
        "\n",
        "def get_inlet_function_from_gpt(prompt):\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        temperature=0\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "def upload_image():\n",
        "    uploaded = files.upload()\n",
        "    for filename in uploaded.keys():\n",
        "        return filename\n",
        "\n",
        "# === Safe Function Runner with Global Patch for `label` ===\n",
        "def run_generated_inlet_function(code_str, image_array):\n",
        "    import scipy.ndimage\n",
        "    from scipy.ndimage import label as scipy_label\n",
        "\n",
        "    code_str = extract_python_code(code_str)\n",
        "\n",
        "    # Patch if `label` is referenced\n",
        "    if \"label(\" in code_str and \"from scipy.ndimage import label\" not in code_str:\n",
        "        code_str = \"from scipy.ndimage import label\\n\" + code_str\n",
        "\n",
        "    globals()[\"label\"] = scipy_label  # ensure label() resolves\n",
        "\n",
        "    local_vars = {}\n",
        "    try:\n",
        "        exec(code_str, globals(), local_vars)\n",
        "        inlet_thicknesses = local_vars.get(\"inlet_thicknesses\")\n",
        "        if inlet_thicknesses is None:\n",
        "            raise ValueError(\"Function `inlet_thicknesses()` not found.\")\n",
        "        return inlet_thicknesses(image_array)\n",
        "    except Exception as e:\n",
        "        raise RuntimeError(f\"Failed to execute generated code: {e}\")\n",
        "\n",
        "# === MAIN LOOP ===\n",
        "attempts = 0\n",
        "mae_list = []\n",
        "all_errors = []\n",
        "\n",
        "while attempts < 10:\n",
        "    print(f\"\\n📤 Upload a PNG image for attempt {attempts + 1}\")\n",
        "    image_path = upload_image()\n",
        "\n",
        "    image = Image.open(image_path).convert('L')\n",
        "    image_array = np.array(image)\n",
        "\n",
        "    actual_thickness = inlet_thicknesses_actual(image_path)\n",
        "\n",
        "    if attempts == 0:\n",
        "        prompt = base_prompt\n",
        "    else:\n",
        "        prompt = base_prompt + f\"\\n\\nFeedback: Your previous estimate had MAE = {mae_list[-1]:.4f}. Please improve the inlet_thicknesses() function.\"\n",
        "\n",
        "    print(\"🔁 Calling ChatGPT for inlet_thicknesses() function...\")\n",
        "    code = get_inlet_function_from_gpt(prompt)\n",
        "    print(\"🧠 Function received from GPT:\\n\", code)\n",
        "\n",
        "    try:\n",
        "        pred_thickness = run_generated_inlet_function(code, image_array)\n",
        "    except Exception as e:\n",
        "        print(\"❌ Error running the generated function:\", e)\n",
        "        mae_list.append(1.0)\n",
        "        attempts += 1\n",
        "        continue\n",
        "\n",
        "    error = abs(pred_thickness - actual_thickness)\n",
        "    all_errors.append(error)\n",
        "    mae = error if attempts == 0 else np.mean(all_errors)\n",
        "    mae_list.append(mae)\n",
        "\n",
        "    print(f\"\\n✅ Attempt {attempts + 1}:\")\n",
        "    print(f\"Predicted Avg Inlet Thickness: {pred_thickness:.4f}\")\n",
        "    print(f\"Actual Avg Inlet Thickness:    {actual_thickness:.4f}\")\n",
        "    print(f\"Absolute Error:                {error:.4f}\")\n",
        "    print(f\"MAE:                           {mae:.4f}\")\n",
        "\n",
        "    if mae < 0.1:\n",
        "        print(\"\\n🎯 Success: MAE is acceptable. Returning the final inlet_thicknesses() function:\\n\")\n",
        "        print(extract_python_code(code))\n",
        "        break\n",
        "    else:\n",
        "        print(\"\\n⚠️ Not accurate enough. Please upload another image to improve the function.\\n\")\n",
        "\n",
        "    attempts += 1\n",
        "\n",
        "# === PLOT MAE ===\n",
        "plt.plot(range(1, len(mae_list)+1), mae_list, marker='o')\n",
        "plt.title(\"Mean Absolute Error (MAE) for inlet_thicknesses()\")\n",
        "plt.xlabel(\"Attempt\")\n",
        "plt.ylabel(\"MAE\")\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ifUUVpO_bQ24",
      "metadata": {
        "id": "ifUUVpO_bQ24"
      },
      "source": [
        "##Test perimeter function\n",
        "MAE < 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "o-TEKbRtbW44",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "id": "o-TEKbRtbW44",
        "outputId": "73b8004c-c35d-4e8b-963c-f7b33ad4651d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "📤 Upload a PNG image for attempt 1\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'files' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4-4130516232.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0mattempts\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\n📤 Upload a PNG image for attempt {attempts + 1}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m     \u001b[0mimage_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupload_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'L'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-4-4130516232.py\u001b[0m in \u001b[0;36mupload_image\u001b[0;34m()\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mupload_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m     \u001b[0muploaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0muploaded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'files' is not defined"
          ]
        }
      ],
      "source": [
        "# === GPT sees these two helpers ===\n",
        "subtract_inlet_definition = \"\"\"\n",
        "def subtract_inlet(array):\n",
        "    first_col = array[:, 0]\n",
        "    thicknesses = []\n",
        "    current_run = 0\n",
        "    for val in first_col:\n",
        "        if val == 0:\n",
        "            current_run += 1\n",
        "        else:\n",
        "            if current_run > 0:\n",
        "                thicknesses.append(current_run)\n",
        "            current_run = 0\n",
        "    if current_run > 0:\n",
        "        thicknesses.append(current_run)\n",
        "    return sum(thicknesses)\n",
        "\"\"\"\n",
        "\n",
        "subtract_outlet_definition = \"\"\"\n",
        "def subtract_outlet(array):\n",
        "    last_col = array[:, -1]\n",
        "    thicknesses = []\n",
        "    current_run = 0\n",
        "    for val in last_col:\n",
        "        if val == 0:\n",
        "            current_run += 1\n",
        "        else:\n",
        "            if current_run > 0:\n",
        "                thicknesses.append(current_run)\n",
        "            current_run = 0\n",
        "    if current_run > 0:\n",
        "        thicknesses.append(current_run)\n",
        "    return sum(thicknesses)\n",
        "\"\"\"\n",
        "\n",
        "base_prompt = f\"\"\"\n",
        "Below are two helper functions used in the image analysis task:\n",
        "\n",
        "{subtract_inlet_definition}\n",
        "\n",
        "{subtract_outlet_definition}\n",
        "\n",
        "Now, write a function `perimeter(array)` that calculates the perimeter of the black (fluid) region in a binary numpy array.\n",
        "- The fluid regions are black (0); background is white (1).\n",
        "- Use OpenCV or numpy to find contours.\n",
        "- Pad the array if needed to ensure contour detection.\n",
        "- Subtract inlet and outlet channel sizes using the two helper functions above.\n",
        "- Return a float representing the fluid region perimeter.\n",
        "\"\"\"\n",
        "\n",
        "# === Ground Truth Function (GPT does NOT see this) ===\n",
        "def perimeter_actual(image_path):\n",
        "    image = Image.open(image_path)\n",
        "    grayscale_image = image.convert('L')\n",
        "    array = np.array(grayscale_image) > 128\n",
        "    array = array.squeeze()\n",
        "\n",
        "    inlet = subtract_inlet_actual(array)\n",
        "    outlet = subtract_outlet_actual(array)\n",
        "\n",
        "    array = np.pad(array, pad_width=1, mode='constant', constant_values=0)\n",
        "    img = cv2.cvtColor(array.astype(np.uint8), cv2.COLOR_GRAY2BGR)\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    gray = cv2.convertScaleAbs(gray)\n",
        "\n",
        "    contours, _ = cv2.findContours(gray, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    if contours:\n",
        "        height, width = array.shape\n",
        "        corner_points = np.array([[0, 0], [width - 1, 0], [width - 1, height - 1], [0, height - 1]])\n",
        "        corner_points_list = corner_points.tolist()\n",
        "        filtered_contours = []\n",
        "\n",
        "        for cnt in contours:\n",
        "            cnt_array = cnt.reshape(-1, 2)\n",
        "            filtered_cnt = cnt_array[~np.any(np.isin(cnt_array, corner_points_list), axis=1)]\n",
        "            filtered_contours.append(filtered_cnt)\n",
        "\n",
        "        total_perimeter = sum(cv2.arcLength(cnt, True) for cnt in filtered_contours)\n",
        "        actual_perimeter = total_perimeter - 2*514 - (2 * 258 - inlet - outlet)\n",
        "        return actual_perimeter\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "def subtract_inlet_actual(array):\n",
        "    first_col = array[:, 0]\n",
        "    thicknesses = []\n",
        "    current_run = 0\n",
        "    for val in first_col:\n",
        "        if val == 0:\n",
        "            current_run += 1\n",
        "        else:\n",
        "            if current_run > 0:\n",
        "                thicknesses.append(current_run)\n",
        "            current_run = 0\n",
        "    if current_run > 0:\n",
        "        thicknesses.append(current_run)\n",
        "    return sum(thicknesses)\n",
        "\n",
        "def subtract_outlet_actual(array):\n",
        "    last_col = array[:, -1]\n",
        "    thicknesses = []\n",
        "    current_run = 0\n",
        "    for val in last_col:\n",
        "        if val == 0:\n",
        "            current_run += 1\n",
        "        else:\n",
        "            if current_run > 0:\n",
        "                thicknesses.append(current_run)\n",
        "            current_run = 0\n",
        "    if current_run > 0:\n",
        "        thicknesses.append(current_run)\n",
        "    return sum(thicknesses)\n",
        "\n",
        "# === Utilities ===\n",
        "def extract_python_code(response_text):\n",
        "    matches = re.findall(r\"```(?:python)?(.*?)```\", response_text, re.DOTALL)\n",
        "    return matches[0].strip() if matches else response_text.strip()\n",
        "\n",
        "def get_perimeter_function_from_gpt(prompt):\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        temperature=0\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "def upload_image():\n",
        "    uploaded = files.upload()\n",
        "    for filename in uploaded.keys():\n",
        "        return filename\n",
        "\n",
        "# === Safe runner with global patches ===\n",
        "def run_generated_perimeter_function(code_str, image_array):\n",
        "    import cv2\n",
        "    import numpy as np\n",
        "\n",
        "    # Convert boolean to uint8 (0 or 255) so OpenCV can handle it\n",
        "    if image_array.dtype == bool:\n",
        "        image_array = (~image_array).astype(np.uint8) * 255  # fluid = 0, background = 255\n",
        "    elif image_array.dtype != np.uint8:\n",
        "        image_array = image_array.astype(np.uint8)\n",
        "\n",
        "    code_str = extract_python_code(code_str)\n",
        "\n",
        "    # Inject known helpers\n",
        "    global_vars = {}\n",
        "    exec(subtract_inlet_definition, global_vars)\n",
        "    exec(subtract_outlet_definition, global_vars)\n",
        "\n",
        "    # Patch OpenCV and numpy imports if needed\n",
        "    if \"cv2\" in code_str and \"import cv2\" not in code_str:\n",
        "        code_str = \"import cv2\\n\" + code_str\n",
        "    if \"np.\" in code_str and \"import numpy as np\" not in code_str:\n",
        "        code_str = \"import numpy as np\\n\" + code_str\n",
        "\n",
        "    # Execute the function code and call it\n",
        "    exec(code_str, global_vars)\n",
        "    perimeter_fn = global_vars.get(\"perimeter\")\n",
        "    if perimeter_fn is None:\n",
        "        raise ValueError(\"Function `perimeter()` not found in generated code.\")\n",
        "    return perimeter_fn(image_array)\n",
        "\n",
        "\n",
        "# === MAIN LOOP ===\n",
        "attempts = 0\n",
        "mae_list = []\n",
        "all_errors = []\n",
        "\n",
        "while attempts < 10:\n",
        "    print(f\"\\n📤 Upload a PNG image for attempt {attempts + 1}\")\n",
        "    image_path = upload_image()\n",
        "\n",
        "    image = Image.open(image_path).convert('L')\n",
        "    image_array = np.array(image) > 128  # binary format for input\n",
        "\n",
        "    actual_value = perimeter_actual(image_path)\n",
        "\n",
        "    prompt = base_prompt if attempts == 0 else base_prompt + f\"\\n\\nFeedback: Your last estimate had MAE = {mae_list[-1]:.4f}. Please refine the function.\"\n",
        "\n",
        "    print(\"🔁 Calling ChatGPT for perimeter() function...\")\n",
        "    code = get_perimeter_function_from_gpt(prompt)\n",
        "    print(\"🧠 Function received from GPT:\\n\", code)\n",
        "\n",
        "    try:\n",
        "        pred_value = run_generated_perimeter_function(code, image_array)\n",
        "    except Exception as e:\n",
        "        print(\"❌ Error running the generated function:\", e)\n",
        "        mae_list.append(100)  # Penalize failure\n",
        "        attempts += 1\n",
        "        continue\n",
        "\n",
        "    error = abs(pred_value - actual_value)\n",
        "    all_errors.append(error)\n",
        "    mae = error if attempts == 0 else np.mean(all_errors)\n",
        "    mae_list.append(mae)\n",
        "\n",
        "    print(f\"\\n✅ Attempt {attempts + 1}:\")\n",
        "    print(f\"Predicted Perimeter: {pred_value:.2f}\")\n",
        "    print(f\"Actual Perimeter:    {actual_value:.2f}\")\n",
        "    print(f\"Absolute Error:      {error:.2f}\")\n",
        "    print(f\"MAE:                 {mae:.4f}\")\n",
        "\n",
        "    if mae < 100:\n",
        "        print(\"\\n🎯 Success! Final GPT-generated `perimeter()` function:\\n\")\n",
        "        print(extract_python_code(code))\n",
        "        break\n",
        "    else:\n",
        "        print(\"\\n⚠️ Not accurate enough. Please upload another image to improve it.\\n\")\n",
        "\n",
        "    attempts += 1\n",
        "\n",
        "# === PLOT MAE ===\n",
        "plt.plot(range(1, len(mae_list)+1), mae_list, marker='o')\n",
        "plt.title(\"Mean Absolute Error (MAE) for perimeter()\")\n",
        "plt.xlabel(\"Attempt\")\n",
        "plt.ylabel(\"MAE\")\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ED3LeTK9fjG5",
      "metadata": {
        "id": "ED3LeTK9fjG5"
      },
      "source": [
        "##Test connectivity\n",
        "Failed for design_80 (❌ Error running the generated function: Failed to execute generated code: name 'count_segments' is not defined), but works for design_167 (0 MAE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6VR29XnLfmqa",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6VR29XnLfmqa",
        "outputId": "367da81f-43bf-4b86-d216-14c677cf4a6e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "📤 Upload a PNG image for attempt 1\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-bd68d0d2-d138-4f21-8c0c-9fd43dd097e2\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-bd68d0d2-d138-4f21-8c0c-9fd43dd097e2\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving design_80.png to design_80 (1).png\n",
            "🔁 Calling ChatGPT for connectivity() function...\n",
            "🧠 Function received from GPT:\n",
            " To solve this problem, we need to analyze the connectivity of fluid channels in a 2D binary or grayscale numpy array. The goal is to count the number of times fluid channels diverge or converge as we move from one column to the next. Here's how you can implement the `connectivity()` function:\n",
            "\n",
            "```python\n",
            "import numpy as np\n",
            "from scipy.ndimage import label\n",
            "\n",
            "def count_segments(column):\n",
            "    \"\"\"Helper function to count the number of separate fluid segments in a column.\"\"\"\n",
            "    # Consider fluid channels as 0, so we invert the column to find connected components\n",
            "    inverted_column = 1 - column\n",
            "    # Label connected components\n",
            "    labeled_array, num_features = label(inverted_column)\n",
            "    return num_features\n",
            "\n",
            "def connectivity(array):\n",
            "    # Ensure the input is a numpy array\n",
            "    array = np.asarray(array)\n",
            "    \n",
            "    # Get the number of columns\n",
            "    num_columns = array.shape[1]\n",
            "    \n",
            "    # Initialize the previous segment count\n",
            "    prev_segment_count = count_segments(array[:, 0])\n",
            "    \n",
            "    # Initialize the event count\n",
            "    event_count = 0\n",
            "    \n",
            "    # Iterate over each column starting from the second one\n",
            "    for col in range(1, num_columns):\n",
            "        # Count the number of segments in the current column\n",
            "        current_segment_count = count_segments(array[:, col])\n",
            "        \n",
            "        # If the number of segments changes, increment the event count\n",
            "        if current_segment_count != prev_segment_count:\n",
            "            event_count += 1\n",
            "        \n",
            "        # Update the previous segment count\n",
            "        prev_segment_count = current_segment_count\n",
            "    \n",
            "    return event_count\n",
            "\n",
            "# Example usage:\n",
            "# array = np.array([[1, 0, 0, 1],\n",
            "#                   [0, 0, 1, 1],\n",
            "#                   [1, 1, 0, 0],\n",
            "#                   [0, 0, 0, 1]])\n",
            "# print(connectivity(array))  # Output will depend on the specific array structure\n",
            "```\n",
            "\n",
            "### Explanation:\n",
            "\n",
            "1. **Inversion and Labeling**: Since fluid channels are represented by 0s, we invert the column (using `1 - column`) to treat fluid channels as 1s for the purpose of labeling connected components. This allows us to use `scipy.ndimage.label` to count the number of connected components (fluid segments) in each column.\n",
            "\n",
            "2. **Counting Segments**: The `count_segments` function counts the number of separate fluid segments in a given column by labeling connected components.\n",
            "\n",
            "3. **Iterating Through Columns**: We iterate through each column of the array, starting from the second column. For each column, we count the number of fluid segments and compare it to the previous column's segment count.\n",
            "\n",
            "4. **Counting Events**: Each time the number of segments changes between consecutive columns, we increment the `event_count`.\n",
            "\n",
            "5. **Return the Total Count**: Finally, the function returns the total number of divergence or convergence events detected across the width of the array.\n",
            "❌ Error running the generated function: Failed to execute generated code: name 'count_segments' is not defined\n",
            "\n",
            "📤 Upload a PNG image for attempt 2\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-736a7113-8827-42b7-97ec-0fe57d5ce20e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-736a7113-8827-42b7-97ec-0fe57d5ce20e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving design_167.png to design_167.png\n",
            "🔁 Calling ChatGPT for connectivity() function...\n",
            "🧠 Function received from GPT:\n",
            " To solve this problem, we need to analyze the 2D array column by column and detect changes in the number of separate vertical fluid segments (black pixel segments) between consecutive columns. Each time the number of segments changes, it indicates a divergence or convergence event.\n",
            "\n",
            "Here's a step-by-step approach to implement the `connectivity()` function:\n",
            "\n",
            "1. **Identify Segments in a Column**: For each column, identify contiguous segments of black pixels (value 0). This can be done by iterating through the column and counting transitions from non-black to black pixels.\n",
            "\n",
            "2. **Compare Consecutive Columns**: For each pair of consecutive columns, compare the number of segments. If the number of segments changes, it indicates a divergence or convergence event.\n",
            "\n",
            "3. **Count Events**: Keep a count of how many times these changes occur as you move from the first to the last column.\n",
            "\n",
            "Here's the implementation of the `connectivity()` function:\n",
            "\n",
            "```python\n",
            "import numpy as np\n",
            "\n",
            "def count_segments(column):\n",
            "    \"\"\"Count the number of contiguous black pixel segments in a column.\"\"\"\n",
            "    segments = 0\n",
            "    in_segment = False\n",
            "    for pixel in column:\n",
            "        if pixel == 0 and not in_segment:\n",
            "            # Start of a new segment\n",
            "            segments += 1\n",
            "            in_segment = True\n",
            "        elif pixel != 0:\n",
            "            # End of a segment\n",
            "            in_segment = False\n",
            "    return segments\n",
            "\n",
            "def connectivity(array):\n",
            "    \"\"\"Count the number of divergence or convergence events in the array.\"\"\"\n",
            "    if array.ndim != 2:\n",
            "        raise ValueError(\"Input must be a 2D array.\")\n",
            "    \n",
            "    num_rows, num_cols = array.shape\n",
            "    if num_cols < 2:\n",
            "        return 0  # No events possible with less than 2 columns\n",
            "    \n",
            "    # Initialize the count of events\n",
            "    event_count = 0\n",
            "    \n",
            "    # Count segments in the first column\n",
            "    previous_segments = count_segments(array[:, 0])\n",
            "    \n",
            "    # Iterate over each column starting from the second\n",
            "    for col in range(1, num_cols):\n",
            "        current_segments = count_segments(array[:, col])\n",
            "        \n",
            "        # Check if the number of segments has changed\n",
            "        if current_segments != previous_segments:\n",
            "            event_count += 1\n",
            "        \n",
            "        # Update previous_segments for the next iteration\n",
            "        previous_segments = current_segments\n",
            "    \n",
            "    return event_count\n",
            "\n",
            "# Example usage:\n",
            "# array = np.array([[0, 0, 1, 0],\n",
            "#                   [0, 1, 1, 0],\n",
            "#                   [1, 1, 0, 0],\n",
            "#                   [0, 0, 0, 1]])\n",
            "# print(connectivity(array))  # Output: 3\n",
            "```\n",
            "\n",
            "### Explanation:\n",
            "- **count_segments**: This helper function counts the number of contiguous segments of black pixels in a given column.\n",
            "- **connectivity**: This function iterates over each column, uses `count_segments` to determine the number of segments, and compares it with the previous column's segment count to detect changes.\n",
            "- **Event Counting**: Each change in the number of segments between consecutive columns is counted as an event.\n",
            "\n",
            "This approach ensures that we accurately count the number of divergence or convergence events in the fluid channels represented by the 2D array.\n",
            "❌ Error running the generated function: Failed to execute generated code: name 'count_segments' is not defined\n",
            "\n",
            "📤 Upload a PNG image for attempt 3\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-50cdaccf-d266-45cc-a7b9-d3ace02783fe\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-50cdaccf-d266-45cc-a7b9-d3ace02783fe\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving design_161.png to design_161.png\n",
            "🔁 Calling ChatGPT for connectivity() function...\n",
            "🧠 Function received from GPT:\n",
            " To solve this problem, we need to analyze the 2D numpy array column by column to detect changes in the number of separate vertical fluid segments. A fluid segment is defined as a contiguous vertical sequence of black pixels (value 0). We will count the number of segments in each column and then compare consecutive columns to detect changes in the number of segments, which indicate either a merge or a split.\n",
            "\n",
            "Here's a step-by-step approach to implement the `connectivity()` function:\n",
            "\n",
            "1. Iterate through each column of the array.\n",
            "2. For each column, count the number of separate fluid segments.\n",
            "3. Compare the number of segments in the current column with the previous column.\n",
            "4. If the number of segments changes, increment the event count.\n",
            "5. Return the total number of change events.\n",
            "\n",
            "Here's the implementation:\n",
            "\n",
            "```python\n",
            "import numpy as np\n",
            "\n",
            "def count_segments(column):\n",
            "    \"\"\"Helper function to count the number of separate fluid segments in a column.\"\"\"\n",
            "    # Find where the column has black pixels (value 0)\n",
            "    black_pixels = (column == 0)\n",
            "    # Count transitions from False to True in the black_pixels array\n",
            "    # This indicates the start of a new segment\n",
            "    segments = 0\n",
            "    in_segment = False\n",
            "    for pixel in black_pixels:\n",
            "        if pixel and not in_segment:\n",
            "            segments += 1\n",
            "            in_segment = True\n",
            "        elif not pixel:\n",
            "            in_segment = False\n",
            "    return segments\n",
            "\n",
            "def connectivity(array):\n",
            "    # Ensure the input is a numpy array\n",
            "    array = np.array(array)\n",
            "    \n",
            "    # Initialize the number of change events\n",
            "    change_events = 0\n",
            "    \n",
            "    # Get the number of columns\n",
            "    num_columns = array.shape[1]\n",
            "    \n",
            "    # Initialize the previous segment count\n",
            "    previous_segments = count_segments(array[:, 0])\n",
            "    \n",
            "    # Iterate over each column starting from the second one\n",
            "    for col in range(1, num_columns):\n",
            "        current_segments = count_segments(array[:, col])\n",
            "        \n",
            "        # Check if the number of segments has changed\n",
            "        if current_segments != previous_segments:\n",
            "            change_events += 1\n",
            "        \n",
            "        # Update the previous segment count\n",
            "        previous_segments = current_segments\n",
            "    \n",
            "    return change_events\n",
            "\n",
            "# Example usage:\n",
            "# array = np.array([[1, 0, 0, 1],\n",
            "#                   [0, 0, 1, 1],\n",
            "#                   [1, 1, 0, 0],\n",
            "#                   [0, 0, 0, 1]])\n",
            "# print(connectivity(array))  # Output will depend on the specific array structure\n",
            "```\n",
            "\n",
            "### Explanation:\n",
            "- **`count_segments(column)`**: This helper function counts the number of separate fluid segments in a given column by detecting transitions from non-black to black pixels.\n",
            "- **`connectivity(array)`**: This function iterates through each column, uses `count_segments` to determine the number of segments, and compares it with the previous column to detect changes. Each change is counted as an event.\n",
            "\n",
            "This approach ensures that we accurately count the number of times fluid channels diverge or converge across the array.\n",
            "❌ Error running the generated function: Failed to execute generated code: name 'count_segments' is not defined\n",
            "\n",
            "📤 Upload a PNG image for attempt 4\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-55275fc6-b453-42ce-9b35-fefdd29c314e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-55275fc6-b453-42ce-9b35-fefdd29c314e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "base_prompt = \"\"\"Write a Python function called `connectivity()` that takes a 2D binary or grayscale numpy array as input and returns an integer count of how many times fluid channels diverge or converge.\n",
        "\n",
        "- Fluid channels are black (pixel = 0).\n",
        "- In each vertical column, you can detect how many separate vertical fluid segments exist.\n",
        "- Count an event each time the number of segments changes between two consecutive columns (i.e., merge or split occurs).\n",
        "- The function should return the total number of such change events across the width of the array.\"\"\"\n",
        "\n",
        "# === Hidden Ground Truth Function ===\n",
        "def connectivity_actual(image_path):\n",
        "    image = Image.open(image_path)\n",
        "    grayscale_image = image.convert('L')\n",
        "    array = np.array(grayscale_image) > 128\n",
        "\n",
        "    change_count = 0\n",
        "    for col_index in range(array.shape[1] - 1):\n",
        "        prev = int(np.round(np.sum(array[:-1, col_index] != array[1:, col_index]) / 2))\n",
        "        curr = int(np.round(np.sum(array[:-1, col_index + 1] != array[1:, col_index + 1]) / 2))\n",
        "        if prev != curr:\n",
        "            change_count += 1\n",
        "    return change_count\n",
        "\n",
        "# === Utilities ===\n",
        "def extract_python_code(response_text):\n",
        "    matches = re.findall(r\"```(?:python)?(.*?)```\", response_text, re.DOTALL)\n",
        "    return matches[0].strip() if matches else response_text.strip()\n",
        "\n",
        "def get_connectivity_function_from_gpt(prompt):\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        temperature=0\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "def upload_image():\n",
        "    uploaded = files.upload()\n",
        "    for filename in uploaded.keys():\n",
        "        return filename\n",
        "\n",
        "def run_generated_connectivity_function(code_str, image_array):\n",
        "    import numpy as np\n",
        "\n",
        "    # Ensure binary format (black = 0, white = 1)\n",
        "    if image_array.dtype == bool:\n",
        "        image_array = (~image_array).astype(np.uint8)\n",
        "    elif image_array.dtype != np.uint8:\n",
        "        image_array = (image_array < 128).astype(np.uint8)\n",
        "\n",
        "    code_str = extract_python_code(code_str)\n",
        "\n",
        "    # Fallback helper: count_segments\n",
        "    fallback_count_segments = \"\"\"\n",
        "def count_segments(column):\n",
        "    return int(np.round(np.sum(column[:-1] != column[1:]) / 2))\n",
        "\"\"\"\n",
        "\n",
        "    # Inject fallback if GPT uses but doesn’t define it\n",
        "    if \"count_segments(\" in code_str and \"def count_segments\" not in code_str:\n",
        "        code_str = fallback_count_segments + \"\\n\" + code_str\n",
        "\n",
        "    local_vars = {}\n",
        "    try:\n",
        "        exec(code_str, globals(), local_vars)\n",
        "        connectivity_fn = local_vars.get(\"connectivity\")\n",
        "        if connectivity_fn is None:\n",
        "            raise ValueError(\"Function `connectivity()` not found.\")\n",
        "        return connectivity_fn(image_array)\n",
        "    except Exception as e:\n",
        "        raise RuntimeError(f\"Failed to execute generated code: {e}\")\n",
        "\n",
        "\n",
        "# === MAIN LOOP ===\n",
        "attempts = 0\n",
        "mae_list = []\n",
        "all_errors = []\n",
        "\n",
        "while attempts < 10:\n",
        "    print(f\"\\n📤 Upload a PNG image for attempt {attempts + 1}\")\n",
        "    image_path = upload_image()\n",
        "\n",
        "    image = Image.open(image_path).convert('L')\n",
        "    image_array = np.array(image)\n",
        "\n",
        "    actual_value = connectivity_actual(image_path)\n",
        "\n",
        "    prompt = base_prompt if attempts == 0 else base_prompt + f\"\\n\\nFeedback: Your previous attempt had MAE = {mae_list[-1]:.4f}. Please refine the function.\"\n",
        "\n",
        "    print(\"🔁 Calling ChatGPT for connectivity() function...\")\n",
        "    code = get_connectivity_function_from_gpt(prompt)\n",
        "    print(\"🧠 Function received from GPT:\\n\", code)\n",
        "\n",
        "    try:\n",
        "        pred_value = run_generated_connectivity_function(code, image_array)\n",
        "    except Exception as e:\n",
        "        print(\"❌ Error running the generated function:\", e)\n",
        "        mae_list.append(100)\n",
        "        attempts += 1\n",
        "        continue\n",
        "\n",
        "    error = abs(pred_value - actual_value)\n",
        "    all_errors.append(error)\n",
        "    mae = error if attempts == 0 else np.mean(all_errors)\n",
        "    mae_list.append(mae)\n",
        "\n",
        "    print(f\"\\n✅ Attempt {attempts + 1}:\")\n",
        "    print(f\"Predicted Connectivity: {pred_value}\")\n",
        "    print(f\"Actual Connectivity:    {actual_value}\")\n",
        "    print(f\"Absolute Error:         {error}\")\n",
        "    print(f\"MAE:                    {mae:.4f}\")\n",
        "\n",
        "    if mae < 0.1:\n",
        "        print(\"\\n🎯 Success: MAE is acceptable. Final GPT-generated `connectivity()` function:\\n\")\n",
        "        print(extract_python_code(code))\n",
        "        break\n",
        "    else:\n",
        "        print(\"\\n⚠️ Not accurate enough. Please upload another image to improve.\\n\")\n",
        "\n",
        "    attempts += 1\n",
        "\n",
        "# === PLOT MAE ===\n",
        "plt.plot(range(1, len(mae_list)+1), mae_list, marker='o')\n",
        "plt.title(\"Mean Absolute Error (MAE) for connectivity()\")\n",
        "plt.xlabel(\"Attempt\")\n",
        "plt.ylabel(\"MAE\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8d6a193",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "id": "c8d6a193",
        "outputId": "12f4b4b6-22a7-4d43-c6ff-75b0fd835ee6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-de936fa0-432c-43d1-8aa4-a3c252113a4e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-de936fa0-432c-43d1-8aa4-a3c252113a4e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving design_80.png to design_80.png\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Step 1: Upload the file\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Step 2: Load and display the image using Pillow and matplotlib\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Automatically use the uploaded file name\n",
        "image_path = list(uploaded.keys())[0]\n",
        "img = Image.open(image_path)\n",
        "\n",
        "# Optional: convert image to NumPy array\n",
        "img_array = np.array(img)\n",
        "\n",
        "# Display the image\n",
        "plt.imshow(img_array)\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d46f7f4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7d46f7f4",
        "outputId": "c584b0bf-7f79-4d74-a63c-4b32326b2edd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.32230377197265625\n",
            "2\n",
            "0.18359375\n",
            "0.41015625\n",
            "1488.0508583784103\n",
            "3\n"
          ]
        }
      ],
      "source": [
        "print(find_vof(image_path))\n",
        "print(num_outlets_actual(image_path))\n",
        "print(outlet_thicknesses_actual(image_path))\n",
        "print(inlet_thicknesses_actual(image_path))\n",
        "print(perimeter_actual(image_path))\n",
        "print(connectivity_actual(image_path))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}